{
  "cells": [
    {
      "metadata": {
        "_uuid": "8fbf02af18f3c8eb140f4a2215001fd97736fc95"
      },
      "cell_type": "markdown",
      "source": "**Imports**"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "c00c0933eb6456fbb3c2ec9fdceae8e63f48d06a"
      },
      "cell_type": "code",
      "source": "import gc\nfrom datetime import datetime, timedelta\nimport numpy as np\nimport pandas as pd\nfrom lightgbm import LGBMClassifier\nimport lightgbm as lgb\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport plotly.offline as py\npy.init_notebook_mode(connected=True)\nimport plotly.graph_objs as go\nimport plotly.tools as tls\nfrom wordcloud import WordCloud\nfrom nltk.corpus import stopwords\nfrom sklearn import preprocessing\nfrom sklearn.ensemble import ExtraTreesClassifier\nfrom sklearn.metrics import log_loss, r2_score, mean_squared_error, mean_absolute_error\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom skopt import gp_minimize\nfrom skopt.plots import plot_convergence\nimport json\n\n%matplotlib inline",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "6414a1a6295ec2d29307de041ba6426db72f79e3"
      },
      "cell_type": "markdown",
      "source": "**Setup Environment**"
    },
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true
      },
      "cell_type": "code",
      "source": "from kaggle.competitions import twosigmanews\nenv = twosigmanews.make_env()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "5e1013aa0f7b91b8aacafd92bd141f1dafad269a"
      },
      "cell_type": "markdown",
      "source": "**Get Training Data**"
    },
    {
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": true
      },
      "cell_type": "code",
      "source": "(market_train, news_train) = env.get_training_data()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "5c7ff3691b88d4c13de46ea229c93d7e1af6146c"
      },
      "cell_type": "code",
      "source": "market_train.describe()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "622bd37d2870f46ed5646feb8eb184360db9ad1e"
      },
      "cell_type": "code",
      "source": "market_train.shape",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "415f5d5f9b53dad20c0324bf91be7e07991f6369"
      },
      "cell_type": "markdown",
      "source": "**Exploratory Data Analysis**"
    },
    {
      "metadata": {
        "_uuid": "7df5f73dda5ac152a6a078e49753b1b260ddfa8e"
      },
      "cell_type": "markdown",
      "source": "**Market Data**\n* time(datetime64[ns, UTC]) - the current time (in marketdata, all rows are taken at 22:00 UTC)\n* assetCode(object) - a unique id of an asset\n* assetName(category) - the name that corresponds to a group of assetCodes. These may be \"Unknown\" if the corresponding assetCode does not have any rows in the news data.\n* universe(float64) - a boolean indicating whether or not the instrument on that day will be included in scoring. This value is not provided outside of the training data time period. The trading universe on a given date is the set of instruments that are avilable for trading (the scoring function will not consider instruments that are not in the trading universe). The trading universe changes daily.\n* volume(float64) - trading volume in shares for the day\n* close(float64) - the close price for the day (not adjusted for splits or dividends)\n* open(float64) - the open price for the day (not adjusted for splits or dividends)\n* returnsClosePrevRaw1(float64) - see returns explanation above\n* returnsOpenPrevRaw1(float64) - see returns explanation above\n* returnsClosePrevMktres1(float64) - see returns explanation above\n* returnsOpenPrevMktres1(float64) - see returns explanation above\n* returnsClosePrevRaw10(float64) - see returns explanation above\n* returnsOpenPrevRaw10(float64) - see returns explanation above\n* returnsClosePrevMktres10(float64) - see returns explanation above\n* returnsOpenPrevMktres10(float64) - see returns explanation above\n* returnsOpenNextMktres10(float64) - 10 day, market-residualized return. This is the target variable used in competition scoring. The market data has been filtered such that returnsOpenNextMktres10 is always not null.\n\n**News Data**\n\n* time(datetime64[ns, UTC]) - UTC timestamp showing when the data was available on the feed (second precision)\n* sourceTimestamp(datetime64[ns, UTC]) - UTC timestamp of this news item when it was created\n* firstCreated(datetime64[ns, UTC]) - UTC timestamp for the first version of the item\n* sourceId(object) - an Id for each news item\n* headline(object) - the item's headline\n* urgency(int8) - differentiates story types (1: alert, 3: article)\n* takeSequence(int16) - the take sequence number of the news item, starting at 1. For a given story, alerts and articles have separate sequences.\n* provider(category) - identifier for the organization which provided the news item (e.g. RTRS for Reuters News, BSW for Business Wire)\n* subjects(category) - topic codes and company identifiers that relate to this news item. Topic codes describe the news item's subject matter. These can cover asset classes, geographies, events, industries/sectors, and other types.\n* audiences(category) - identifies which desktop news product(s) the news item belongs to. They are typically tailored to specific audiences. (e.g. \"M\" for Money International News Service and \"FB\" for French General News Service)\n* bodySize(int32) - the size of the current version of the story body in characters\n* companyCount(int8) - the number of companies explicitly listed in the news item in the subjects field\n* headlineTag(object) - the Thomson Reuters headline tag for the news item\n* marketCommentary(bool) - boolean indicator that the item is discussing general market conditions, such as \"After the Bell\" summaries\n* sentenceCount(int16) - the total number of sentences in the news item. Can be used in conjunction with firstMentionSentence to determine the relative position of the first mention in the item.\n* wordCount(int32) - the total number of lexical tokens (words and punctuation) in the news item\n* assetCodes(category) - list of assets mentioned in the item\n* assetName(category) - name of the asset\n* firstMentionSentence(int16) - the first sentence, starting with the headline, in which the scored asset is mentioned.\n1: headline\n2: first sentence of the story body\n3: second sentence of the body, etc\n0: the asset being scored was not found in the news item's headline or body text. As a result, the entire news item's text (headline + body) will be used to determine the sentiment score.\n* relevance(float32) - a decimal number indicating the relevance of the news item to the asset. It ranges from 0 to 1. If the asset is mentioned in the headline, the relevance is set to 1. When the item is an alert (urgency == 1), relevance should be gauged by firstMentionSentence instead.\n* sentimentClass(int8) - indicates the predominant sentiment class for this news item with respect to the asset. The indicated class is the one with the highest probability.\n* sentimentNegative(float32) - probability that the sentiment of the news item was negative for the asset\n* sentimentNeutral(float32) - probability that the sentiment of the news item was neutral for the asset\n* sentimentPositive(float32) - probability that the sentiment of the news item was positive for the asset\n* sentimentWordCount(int32) - the number of lexical tokens in the sections of the item text that are deemed relevant to the asset. This can be used in conjunction with wordCount to determine the proportion of the news item discussing the asset.\n* noveltyCount12H(int16) - The 12 hour novelty of the content within a news item on a particular asset. It is calculated by comparing it with the asset-specific text over a cache of previous news items that contain the asset.\n* noveltyCount24H(int16) - same as above, but for 24 hours\n* noveltyCount3D(int16) - same as above, but for 3 days\n* noveltyCount5D(int16) - same as above, but for 5 days\n* noveltyCount7D(int16) - same as above, but for 7 days\n* volumeCounts12H(int16) - the 12 hour volume of news for each asset. A cache of previous news items is maintained and the number of news items that mention the asset within each of five historical periods is calculated.\n* volumeCounts24H(int16) - same as above, but for 24 hours\n* volumeCounts3D(int16) - same as above, but for 3 days\n* volumeCounts5D(int16) - same as above, but for 5 days\n* volumeCounts7D(int16) - same as above, but for 7 days"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "c6cd2e476c45e4679325dde1d3983d480ae4e9bc"
      },
      "cell_type": "code",
      "source": "data = []\nfor asset in np.random.choice(market_train['assetName'].unique(), 10):\n    asset_df = market_train[(market_train['assetName'] == asset)]\n\n    data.append(go.Scatter(\n        x = asset_df['time'].dt.strftime(date_format='%Y-%m-%d').values,\n        y = asset_df['close'].values,\n        name = asset\n    ))\nlayout = go.Layout(dict(title = \"Closing prices of 10 random assets\",\n                  xaxis = dict(title = 'Month'),\n                  yaxis = dict(title = 'Price (USD)'),\n                  ),legend=dict(\n                orientation=\"h\"))\npy.iplot(dict(data=data, layout=layout), filename='basic-line')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "2c3b6cdc0bbd1ffd1e0e5888e04ae8f30ed131fc"
      },
      "cell_type": "code",
      "source": "data = []\nfor i in [0.05, 0.1, 0.25, 0.5, 0.75, 0.9, 0.95]:\n    price_df = market_train.groupby('time')['close'].quantile(i).reset_index()\n\n    data.append(go.Scatter(\n        x = price_df['time'].dt.strftime(date_format='%Y-%m-%d').values,\n        y = price_df['close'].values,\n        name = f'{i} quantile'\n    ))\nlayout = go.Layout(dict(title = \"Trends of closing prices by quantiles\",\n                  xaxis = dict(title = 'Month'),\n                  yaxis = dict(title = 'Price (USD)'),\n                  ),legend=dict(\n                orientation=\"h\"))\npy.iplot(dict(data=data, layout=layout), filename='basic-line')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "205b4f9ca8d1d2c7373156c7bf7c3082833ade7c"
      },
      "cell_type": "code",
      "source": "data = []\nfor i in [0.05, 0.1, 0.25, 0.5, 0.75, 0.9, 0.95]:\n    price_df = market_train.groupby('time')['returnsOpenNextMktres10'].quantile(i).reset_index()\n\n    data.append(go.Scatter(\n        x = price_df['time'].dt.strftime(date_format='%Y-%m-%d').values,\n        y = price_df['returnsOpenNextMktres10'].values,\n        name = f'{i} quantile'\n    ))\nlayout = go.Layout(dict(title = \"Trends of returnsOpenNextMktres10 by quantiles\",\n                  xaxis = dict(title = 'Month'),\n                  yaxis = dict(title = 'Price (USD)'),\n                  ),legend=dict(\n                orientation=\"h\"),)\npy.iplot(dict(data=data, layout=layout), filename='basic-line')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "8232ba49877b4018380d290447c6e1c018de9f14"
      },
      "cell_type": "code",
      "source": "text = ' '.join(news_train['headline'].str.lower().values[-1000000:])\nstop = set(stopwords.words('english'))\nwordcloud = WordCloud(max_font_size=None, stopwords=stop, background_color='white',\n                      width=1200, height=1000).generate(text)\nplt.figure(figsize=(12, 8))\nplt.imshow(wordcloud)\nplt.title('Top words in headline')\nplt.axis(\"off\")\nplt.show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b41e81efb9d3924550d330f1f345ce2b5f6f5d75"
      },
      "cell_type": "code",
      "source": "(news_train['urgency'].value_counts() / 1000000).plot('bar');\nplt.xticks(rotation=30);\nplt.title('Urgency counts (mln)');",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "409f7724efd21172f42ff52ac066c1fbf08c5e58"
      },
      "cell_type": "code",
      "source": "news_train['provider'].value_counts().head(10)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "c63c84b595cb741d42b33d9ddf3ca15f6f510b83"
      },
      "cell_type": "code",
      "source": "for i, j in zip([-1, 0, 1], ['negative', 'neutral', 'positive']):\n    df_sentiment = news_train.loc[news_train['sentimentClass'] == i, 'assetName']\n    print(f'Top mentioned companies for {j} sentiment are:')\n    print(df_sentiment.value_counts().head(5))\n    print('')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "bf4b64c9906d157950c125ed683fb27e6e8ca099"
      },
      "cell_type": "markdown",
      "source": "**Preprocess Data**"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "0fbdb909639c5c416c111ab8b1fcd6f612d58ddb"
      },
      "cell_type": "code",
      "source": "market_train = market_train.loc[market_train['time'] >= '2010-01-01 22:00:00+0000']\nnews_train = news_train.loc[news_train['time'] >= '2010-01-01 22:00:00+0000']",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "760b44c3995fe9f496c34270885c80844bed4e23"
      },
      "cell_type": "code",
      "source": "def preprocess_news(news_train):\n    drop_list = [\n        'audiences', 'subjects', 'assetName',\n        'headline', 'firstCreated', 'sourceTimestamp',\n    ]\n    news_train.drop(drop_list, axis=1, inplace=True)\n    \n    # Factorize categorical columns\n    for col in ['headlineTag', 'provider', 'sourceId']:\n        news_train[col], uniques = pd.factorize(news_train[col])\n        del uniques\n    \n    # Remove {} and '' from assetCodes column\n    news_train['assetCodes'] = news_train['assetCodes'].apply(lambda x: x[1:-1].replace(\"'\", \"\"))\n    return news_train\n\nnews_train = preprocess_news(news_train)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "69c32d4efa8c592ca07386ed7231ecb6693eb88e"
      },
      "cell_type": "markdown",
      "source": "**Split Asset Codes in News Data**"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "dfee4cbb7bf50210f396883b091a354e5b27671b"
      },
      "cell_type": "code",
      "source": "def unstack_asset_codes(news_train):\n    codes = []\n    indexes = []\n    for i, values in news_train['assetCodes'].iteritems():\n        explode = values.split(\", \")\n        codes.extend(explode)\n        repeat_index = [int(i)]*len(explode)\n        indexes.extend(repeat_index)\n    index_df = pd.DataFrame({'news_index': indexes, 'assetCode': codes})\n    del codes, indexes\n    gc.collect()\n    return index_df\n\nindex_df = unstack_asset_codes(news_train)\nindex_df.head()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "a45eab5178461aeb834a8f1771dae29ca2b5e238"
      },
      "cell_type": "code",
      "source": "def merge_news_on_index(news_train, index_df):\n    news_train['news_index'] = news_train.index.copy()\n\n    # Merge news on unstacked assets\n    news_unstack = index_df.merge(news_train, how='left', on='news_index')\n    news_unstack.drop(['news_index', 'assetCodes', 'sourceId'], axis=1, inplace=True)\n    return news_unstack\n\nnews_unstack = merge_news_on_index(news_train, index_df)\ndel news_train, index_df\ngc.collect()\nnews_unstack.head(3)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "739472f419eb1a4d801d0489309377bf63ae6b8c"
      },
      "cell_type": "markdown",
      "source": "**Group Data**"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "135390dbc1f4ad8ed197e37e9fa6f7c4bce7862b"
      },
      "cell_type": "code",
      "source": "gc.collect()\ndef group_news(news_frame):\n    news_frame['date'] = news_frame.time.dt.date  # Add date column\n    \n    aggregations = ['mean']\n    gp = news_frame.groupby(['assetCode', 'date']).agg(aggregations)\n    gp.columns = pd.Index([\"{}_{}\".format(e[0], e[1]) for e in gp.columns.tolist()])\n    gp.reset_index(inplace=True)\n    # Set datatype to float32\n    float_cols = {c: 'float32' for c in gp.columns if c not in ['assetCode', 'date']}\n    return gp.astype(float_cols)\n\nnews_agg = group_news(news_unstack)\ndel news_unstack; gc.collect()\nnews_agg.head(3)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "d1b1f664ffa6e08a9924bc0bdc1e30338cca2bd8"
      },
      "cell_type": "markdown",
      "source": "**Merge News with Market Data**"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "f2c61d751814dda4e88753d80f1ea42d8c08c2ae"
      },
      "cell_type": "code",
      "source": "market_train['date'] = market_train.time.dt.date\ndf = market_train.merge(news_agg, how='left', on=['assetCode', 'date'])\ndel market_train, news_agg\ngc.collect()\ndf.head(3)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "6c2513942eb14e906007f018f01edef7cf20c779"
      },
      "cell_type": "markdown",
      "source": "**Data Cleanup**"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "55d2dac5d1c6bf26080ee21c8315a32a7e6eb7d7"
      },
      "cell_type": "code",
      "source": "def missing_value_impute(data):\n    grouped_data = data.groupby('assetCode')\n    for i in data.columns:\n        if data[i].dtype == \"object\":\n            data[i] = data[i].fillna(\"other\")\n        elif (data[i].dtype == \"float32\" or data[i].dtype == \"float64\"):\n            data[i] = data[i].fillna(grouped_data[i].mean())\n            data[i] = data[i].fillna(0)\n        else:\n            pass\n    return data",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "020ef139b12d02fad2aee14404c52fb851e296ba",
        "scrolled": false
      },
      "cell_type": "code",
      "source": "gc.collect()\nmissing_value_impute(df)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "35ee413419e18928ccd85299b77e63427481fcfd"
      },
      "cell_type": "code",
      "source": "df.isna().sum()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "scrolled": false,
        "_uuid": "c717611a2d4f07f5ca40bf101cfc32958de2ba25"
      },
      "cell_type": "code",
      "source": "gc.collect()",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'gc' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-35e5c8a5ab93>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'gc' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "1dfddf47e9a31c31d9270b8827572d83f60dbee6"
      },
      "cell_type": "markdown",
      "source": "**Data split**"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "21f29fc90fff6877e80f15cdd1e09cc342f2fd25"
      },
      "cell_type": "code",
      "source": "date = df.date\nnum_target = df.returnsOpenNextMktres10.astype('float32')\nbin_target = (df.returnsOpenNextMktres10 >= 0).astype('int8')\n# universe = df.universe.astype('int8')\n# Drop columns that are not features\nuniverse_data = df['universe']\ntime_data = df['time']\ndf.drop([\n    'returnsOpenNextMktres10', \n    'date', \n    'universe', \n    'assetCode', \n    'assetName', \n    'time'], \n        axis=1, inplace=True)\ndf = df.astype('float32')  # Set all remaining columns to float32 datatype\ngc.collect()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "cf34d6bffc2fb6d140467d4833e791a29c4f43f3"
      },
      "cell_type": "code",
      "source": "x_train, x_test, y_train, y_test, u_train, u_test, t_train, t_test = \\\n    train_test_split(df, bin_target, universe_data, time_data, \n                     test_size=0.10, shuffle=False, random_state=99)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "0d69c4dcdd81ba1218efef1ac68e3092df5bb29d"
      },
      "cell_type": "markdown",
      "source": "**Baseline Model - ExtraTreesClassifier**"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "1cda1d747ac9995041321025fa7e8daf8d2fe6be"
      },
      "cell_type": "code",
      "source": "def plot_model_performance(y, y_hat):\n    print(\"R2 score: \", r2_score(y, y_hat))\n    print('Mean Absolute Error:', mean_absolute_error(y, y_hat))\n    mse = mean_squared_error(y, y_hat)\n    print('Mean Squared Error:', mse)  \n    print('Root Mean Squared Error:', np.sqrt(mse)) ",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "d8e1b42c5fe3bc220159f01b4fd3a6a3d9046070",
        "_kg_hide-input": false,
        "_kg_hide-output": false
      },
      "cell_type": "code",
      "source": "def do_baseline_modeling(x_train, x_test, y_train, y_test):\n    model = ExtraTreesClassifier(bootstrap=True, oob_score=True,\n                                    n_estimators=10, class_weight=\"balanced_subsample\")\n    prev_oob_score = 0.0\n    for i in range(1, 10):\n        gc.collect()\n        model.set_params(n_estimators=i)    \n        model.fit(x_train, y_train)\n        print(model.oob_score_)\n        if i > 1 and (model.oob_score_ - prev_oob_score < 0.05):\n            gc.collect()\n            break\n        prev_oob_score = model.oob_score_\n        gc.collect()\n    y_hat = model.predict(x_test)\n    plot_model_performance(y_test, y_hat)\n    return model",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "3b361cb8eb97f4a3dfb319dac9631b1f260c1823"
      },
      "cell_type": "code",
      "source": "baseline_model = do_baseline_modeling(x_train, x_test, y_train, y_test)\nimp_features = baseline_model.feature_importances_\nprint(imp_features)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "e8984357fc1829bb1f3e2c28f332a83a9a17ad74"
      },
      "cell_type": "markdown",
      "source": "**Hyper parameter Tuning**"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "21cd0db53964a08bb62e86ca8bf1c608b25b11cb"
      },
      "cell_type": "code",
      "source": "def sigma_score(preds, valid_data):\n    df_time = valid_data.params['extra_time']\n    labels = valid_data.get_label()\n    x_t = preds * labels\n    x_t_sum = x_t.groupby(df_time).sum()\n    score = x_t_sum.mean() / x_t_sum.std()\n    return 'sigma_score', score, True",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "7c182fa9ca8033b4e031b8861e05ca20c3d18a48"
      },
      "cell_type": "code",
      "source": "def f(x):\n    gc.collect()\n    print(x)\n    params = {\n        'task': 'train',\n        'boosting_type': 'dart',\n        'learning_rate': x[0],\n        'num_leaves': x[1],\n        'min_data_in_leaf': x[2],\n        'num_iteration': x[3],\n        'max_bin': x[4],\n        'verbose': 1,\n        'objective': 'binary'\n    }\n    d_train = lgb.Dataset(x_train, label=y_train)\n    d_test = lgb.Dataset(x_test, label=y_test)\n    gbm = lgb.train(params,\n            d_train,\n            num_boost_round=100,\n            valid_sets=d_test,\n            early_stopping_rounds=5)\n    \n    print('score: ', mean_squared_error(\n        gbm.predict(x_test, num_iteration=gbm.best_iteration), y_test))\n    gc.collect()\n    return mean_squared_error(\n        gbm.predict(x_test, num_iteration=gbm.best_iteration), y_test)\n\n# optimize params in these ranges\nspaces = [\n    (0.01, 0.3), #learning_rate\n    (3000, 3500), #num_leaves\n    (260, 300), #min_data_in_leaf\n    (800, 1000), #num_iteration\n    (200, 220) #max_bin\n]\n\n# run optimization\nres = gp_minimize(\n    f, spaces,\n    acq_func=\"EI\",\n    n_calls=10) # increase n_calls for more performance\n\n# print tuned params\nprint(res.x)\n\n# plot tuning process\nplot_convergence(res)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b3e34ff89c859776e7f5d04c12086874f1dd2225"
      },
      "cell_type": "code",
      "source": "params = {\n    'learning_rate': res.x[0],\n    'num_leaves': res.x[1],\n    'n_estimators': 200,\n    'min_child_samples': 20,\n    'colsample_bytree': 0.8,\n    'subsample': 1.0,\n    'reg_alpha': 0.8,\n    'reg_lambda': 0.4,\n    'task': 'train',\n    'boosting_type': 'dart',\n    'min_data_in_leaf': res.x[2],\n    'num_iteration': res.x[3],\n    'max_bin': res.x[4],\n    'verbose': 1,\n    'objective': 'binary'\n}\nparams",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "e28e2a44728967267688a767f5ffe6f788f0bb79"
      },
      "cell_type": "markdown",
      "source": "**Train LGBM Model**"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "a8c674812c4767dca46bd48e19597e2298242fb8"
      },
      "cell_type": "code",
      "source": "# params = {\n#     'learning_rate': 0.14360424246380565,\n#     'num_leaves': 170,\n#     'n_estimators': 200,\n#     'min_child_samples': 1500,\n#     'colsample_bytree': 0.8,\n#     'subsample': 1.0,\n#     'reg_alpha': 0.8,\n#     'reg_lambda': 0.4,\n#     'task': 'train',\n#     'boosting_type': 'dart',\n#     'min_data_in_leaf': 500,\n#     'num_iteration': 50,\n#     'max_bin': 50000,\n#     'verbose': 1,\n#     'objective': 'binary'\n# }",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "432aaedef529fb4bbd5700376bad23e76f95265f",
        "scrolled": false
      },
      "cell_type": "code",
      "source": "gc.collect()\nd_train = lgb.Dataset(x_train, label=y_train)\nd_test = lgb.Dataset(x_test, label=y_test)\nclf = lgb.train(params,\n        d_train,\n        num_boost_round=1000,\n        valid_sets=d_test,\n        early_stopping_rounds=5)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "6c228494d804ad659577e822590b1314a7c541ce"
      },
      "cell_type": "code",
      "source": "gc.collect()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "bd46e026ee3e9688972964aa6a4a634fb0a0d305"
      },
      "cell_type": "markdown",
      "source": "**Evaluate LGBM Model**"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "f6c62067dcb9e9f4747245651a3897cd5d364ee3"
      },
      "cell_type": "code",
      "source": "def evaluate_lgbm_model(x_train, x_test, y_train, y_test, params, model):\n    gc.collect()\n    d_train = lgb.Dataset(x_train, label=y_train)\n    d_test = lgb.Dataset(x_test, label=y_test)\n    watchlist = [d_test]\n    model = lgb.train(params, d_train, watchlist, verbose_eval=1)\n    plot_model_performance(y_test, model.predict(x_test))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "fac74339708f628fd183adb2b5d5d6b877d0fe21"
      },
      "cell_type": "code",
      "source": "evaluate_lgbm_model(x_train, x_test, y_train, y_test, params, clf)",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'evaluate_lgbm_model' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-44fde419428e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mevaluate_lgbm_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'evaluate_lgbm_model' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "_uuid": "fe307f50bcc9a46cec2ac446e1443dbd23dd3c8a"
      },
      "cell_type": "markdown",
      "source": "**Feature Importance**"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "6212ff5d7255e22e3d0c3846aa269c681469cceb"
      },
      "cell_type": "code",
      "source": "feat_importance = pd.DataFrame()\nfeat_importance[\"feature\"] = df.columns\nfeat_importance[\"gain\"] = clf.feature_importance(importance_type='gain')\nfeat_importance.sort_values(by='gain', ascending=False, inplace=True)\nplt.figure(figsize=(8,10))\nax = sns.barplot(y=\"feature\", x=\"gain\", data=feat_importance)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "16357f4579ec3645fbe2a4db141ebcada8c012ae"
      },
      "cell_type": "markdown",
      "source": "**Write Submission**"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "8e120342de9a28859edba2a9d2d73e7c8c8d13e8"
      },
      "cell_type": "code",
      "source": "days = env.get_prediction_days()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "52cc8e007afe4dd34c5d78d2ac34469b2dcdc72e"
      },
      "cell_type": "code",
      "source": "def write_submission(model, env, days):\n    for (market_obs_df, news_obs_df, predictions_template_df) in days:\n        news_obs_df = preprocess_news(news_obs_df)\n        # Unstack news\n        index_df = unstack_asset_codes(news_obs_df)\n        news_unstack = merge_news_on_index(news_obs_df, index_df)\n        # Group and and get aggregations (mean)\n        news_obs_agg = group_news(news_unstack)\n\n        # Join market and news frames\n        market_obs_df['date'] = market_obs_df.time.dt.date\n        obs_df = market_obs_df.merge(news_obs_agg, how='left', on=['assetCode', 'date'])\n        del market_obs_df, news_obs_agg, news_obs_df, news_unstack, index_df\n        gc.collect()\n        obs_df = obs_df[obs_df.assetCode.isin(predictions_template_df.assetCode)]\n        dropped_features =  ['universe', 'date', \n                                             'assetCode', 'assetName', 'time']\n        feats = [c for c in obs_df.columns if c not in dropped_features]\n\n        preds = model.predict(obs_df[feats])[:] * 2 - 1\n        sub = pd.DataFrame({'assetCode': obs_df['assetCode'], 'confidence': preds})\n        predictions_template_df = predictions_template_df.merge(sub, how='left').drop(\n            'confidenceValue', axis=1).fillna(0).rename(columns={'confidence':'confidenceValue'})\n        \n        env.predict(predictions_template_df)\n        del obs_df, predictions_template_df, preds, sub\n        gc.collect()\n    env.write_submission_file()\n\nif 'days' not in globals():\n    days = env.get_prediction_days()   \nwrite_submission(clf, env, days)",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}